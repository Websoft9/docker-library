# AnythingLLM


## Guide

### Quick Start

1. Prepare your online LLM or create Ollama application at Websoft9 Console
2. Docker exec to Ollama container and running command `ollama run tinydolphin` to create model
3. Access AnythingLLM setup interface and select online LLM(OpenAI) or Ollama installed before
4. Setting LLM provider for your workspace
5. You can chat with LLM now


## Config


- Multiply Lanuages: Yes

## FAQ
